#!/bin/bash
# filter 0.0.1
# Generated by dx-app-wizard.
#
# Basic execution pattern: Your app will run on a single machine from
# beginning to end.
#
# Your job's input variables (if any) will be loaded as environment
# variables before this script runs.  Any array inputs will be loaded
# as bash arrays.
#
# Any code outside of main() (or any entry point you may add) is
# ALWAYS executed, followed by running the entry point itself.
#
# See https://documentation.dnanexus.com/developer for tutorials on how
# to modify this file.
set -e -x -o pipefail

main() {
    
    echo "Value of input_file: '$input_file'"
    
    # Download the inputs to the worker's local storage
    mkdir -p in/input_file
    dx download "$input_file" -o in/input_file

    # Get the index basename to use
    input_filename=$(dx describe --name "$input_file")
    input_basename=${input_filename%.vcf.gz}
    echo "input file: '$input_filename'"
    echo "input basename: '$input_basename'"
    echo "input dictionary: '$input_file_path'"

    # specify output folder/file
    mkdir -p out/output_file
    output_name="${input_basename}_filtered.vcf.gz"
    echo "output file: '$output_name'"
    
    ####### QC metrics
    # variant missingness
    bcftools +/usr/bin/plugins/fill-tags.so --no-version --threads 4 "$input_file_path" -- -t F_MISSING | \
    bcftools filter --no-version --threads 4 -e 'INFO/F_MISSING>=0.1' -Oz -o out/1.vcf.gz
    
    # split multiallelic variants
    bcftools norm --no-version --threads 4 -m -any --keep-sum AD -Oz -o out/2.vcf.gz out/1.vcf.gz

    # HWE
    bcftools +/usr/bin/plugins/fill-tags.so --no-version --threads 4 out/2.vcf.gz -- -t TYPE,HWE | \
    bcftools filter --no-version --threads 4 -e 'INFO/HWE<=1e-15' -Oz -o out/3.vcf.gz

    # genotype level filtering
    bcftools filter --no-version --threads 4 -Oz -o "$output_name" \
    -e '(INFO/TYPE="SNP" && (FMT/DP<7 || MAX(FMT/AD[:1]/FMT/DP)<=0.15)) || (INFO/TYPE="INDEL" && (FMT/DP<10 || MAX(FMT/AD[:1]/FMT/DP)<=0.20))' out/3.vcf.gz

    # summary file
    COUNT1=$(bcftools view -H --threads 4 out/1.vcf.gz | wc -l)
    COUNT2=$(bcftools view -H --threads 4 out/2.vcf.gz | wc -l)
    COUNT3=$(bcftools view -H --threads 4 out/3.vcf.gz | wc -l)
    COUNT4=$(bcftools view -H --threads 4 "$output_name" | wc -l)
    echo $input_basename $COUNT1 $COUNT2 $COUNT3 $COUNT4 > out/output_file/$input_basename.txt

    mv "$output_name" out/output_file
    #
    # To report any recognized errors in the correct format in
    # $HOME/job_error.json and exit this script, you can use the
    # dx-jobutil-report-error utility as follows:
    #
    # dx-jobutil-report-error "My error message"
    #
    # Note however that this entire bash script is executed with -e
    # when running in the cloud, so any line which returns a nonzero
    # exit code will prematurely exit the script; if no error was
    # reported in the job_error.json file, then the failure reason
    # will be AppInternalError with a generic error message.

    # The following line(s) use the dx command-line tool to upload your file
    # outputs after you have created them on the local file system.  It assumes
    # that you have used the output field name for the filename for each output,
    # but you can change that behavior to suit your needs.  Run "dx upload -h"
    # to see more options to set metadata.

    output_file=$(dx upload out/output_file/*vcf.gz --brief)
    output_summary=$(dx upload out/output_file/*txt --brief)

    # The following line(s) use the utility dx-jobutil-add-output to format and
    # add output variables to your job's output as appropriate for the output
    # class.  Run "dx-jobutil-add-output -h" for more information on what it
    # does.

    dx-jobutil-add-output output_file "$output_file" --class=file
    dx-jobutil-add-output output_summary "$output_summary" --class=file
}
